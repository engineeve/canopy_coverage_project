{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder-decoder Architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following notebook provides development of two encoder-decoder CNN architectures (U-Net and a simple 4-layer architecture). Both models are trained useing the ISPRS dataset of the city of Vaihingen in Germany: (http://www2.isprs.org/commissions/comm3/wg4/2d-sem-label-vaihingen.html).\n",
    "\n",
    "\n",
    "Code for the UNet modle influenced by the following blog:\n",
    "https://www.kaggle.com/toregil/a-lung-u-net-in-keras\n",
    "\n",
    "Code for 4-layer encoder-decoder modle influenced by the following blog:\n",
    "https://blog.keras.io/building-autoencoders-in-keras.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for the UNet modle influenced by the following blog:\n",
    "https://www.kaggle.com/toregil/a-lung-u-net-in-keras\n",
    "\n",
    "Code for 4-layer encoder-decoder modle influenced by the following blog:\n",
    "https://blog.keras.io/building-autoencoders-in-keras.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import keras\n",
    "from keras.models import Model,Sequential\n",
    "from keras.callbacks import ModelCheckpoint,TensorBoard\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPool2D, UpSampling2D, Dropout, Activation,concatenate,MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "import re\n",
    "import pickle\n",
    "from sklearn.metrics import precision_score, f1_score,classification_report,recall_score,precision_recall_fscore_support\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import Image, display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define global variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMG_PATH = '/home/niamh/notebooks/PATCH_BASED/patch_32_stride_18/train_patches/total_train/'\n",
    "GT_PATH = '/home/niamh/notebooks/AUTOENCODER/GT_patches_32_stride18/train_patches/total_train/'\n",
    "\n",
    "# Dimensions of input images for both models\n",
    "IMG_HEIGHT, IMG_WIDTH, CHANNELS = 32, 32, 3\n",
    "\n",
    "# For useing a sample of the trainnig data\n",
    "SAMPLE_RATE = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images = [x for x in sorted(os.listdir(IMG_PATH)) if x[-4:] == '.png']\n",
    "all_images = random.sample(all_images, int(len(all_images)*SAMPLE_RATE))\n",
    "\n",
    "# Initialise array for training  images\n",
    "x_data = np.empty((len(all_images), IMG_HEIGHT, IMG_WIDTH, CHANNELS), dtype='float32')\n",
    "\n",
    "# Initialise array for ground truth of training images\n",
    "y_data = np.empty((len(all_images), IMG_HEIGHT, IMG_WIDTH, CHANNELS), dtype='float32')\n",
    "\n",
    "# Number of training examples\n",
    "train_count = len(all_images)\n",
    "print ('Number of training examples: ',train_count)\n",
    "\n",
    "# Itterate through each image resize, normalize and add to training array \n",
    "for i, name in enumerate(all_images):\n",
    "    im = cv2.imread(IMG_PATH + name, cv2.IMREAD_UNCHANGED).astype(\"int16\").astype('float32')/255.\n",
    "    im = cv2.resize(im, dsize=(IMG_WIDTH, IMG_HEIGHT), interpolation=cv2.INTER_LANCZOS4)\n",
    "    #im = (im - np.min(im)) / (np.max(im) - np.min(im))\n",
    "    x_data[i] = im\n",
    "    \n",
    "    row = str(re.search('row(\\d+)', name).group())\n",
    "    col = str(re.search('col(\\d+)', name).group())\n",
    "    gt = cv2.imread(GT_PATH +name[0:8]+row+'_'+col+'_.png', cv2.IMREAD_UNCHANGED).astype('float32')/255.\n",
    "    gt = cv2.resize(gt, dsize=(IMG_WIDTH, IMG_HEIGHT), interpolation=cv2.INTER_NEAREST)\n",
    "    \n",
    "    y_data[i] = gt\n",
    "    \n",
    "    if i%1000 == 0: print('Processed {} of {}'.format(i, train_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display some examples from the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "plt.figure(figsize=(20, 10)) \n",
    "\n",
    "for i in range(n):\n",
    "    i = i+1\n",
    "    idx = random.randint(0, len(x_data))\n",
    "    \n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i)\n",
    "    plt.imshow(x_data[idx].reshape(IMG_HEIGHT, IMG_WIDTH,3))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    plt.title('Image example '+ str(idx))\n",
    "    \n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + n)\n",
    "    plt.imshow(y_data[idx].reshape(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    plt.title('Ground truth example '+ str(idx))\n",
    "\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 4-Layer Encoder-decoder Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters for model and training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model Params\n",
    "optimizer='adadelta'\n",
    "loss='mean_squared_error'\n",
    "\n",
    "# Training Params\n",
    "best_weights_filepath = '4layer_encoder_decoder_best_weights.hdf5'\n",
    "epochs = 10\n",
    "batch_size = 10\n",
    "validation_split=0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build model architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "\n",
    "# Encoder\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "# Decoder\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "encoder_decoder = Model(input_img, decoded)\n",
    "encoder_decoder.compile(optimizer='adadelta', loss='mean_squared_error', metrics=['accuracy'])\n",
    "encoder_decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile 4-layer encoder-decoder model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_decoder.compile(optimizer=optimizer, loss=loss,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train 4-layer encoder-decoder model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save best weights of model dependent on the lowest validation loss to load for testing\n",
    "mcp = ModelCheckpoint(best_weights_filepath, monitor=\"val_loss\",\n",
    "                      save_best_only=True, save_weights_only=False)\n",
    "\n",
    "# Train model\n",
    "history =encoder_decoder.fit(x_data, y_data,\n",
    "                epochs=epochs,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=True,\n",
    "                validation_split=validation_split,\n",
    "                        callbacks = [mcp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display and record training info:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "loss_fig = plt.figure()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(loss, 'blue', label='Training Loss')\n",
    "plt.plot(val_loss, 'green', label='Validation Loss')\n",
    "plt.xticks(range(0,epochs)[0::2])\n",
    "plt.legend()\n",
    "plt.show()\n",
    "loss_fig.savefig('4layer_encoder_decoder_loss.png')\n",
    "\n",
    "\n",
    "acc_fig = plt.figure()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(acc, 'blue', label='Training Accuracy')\n",
    "plt.plot(val_acc, 'green', label='Validation Accuracy')\n",
    "plt.xticks(range(0,epochs)[0::2])\n",
    "plt.legend()\n",
    "plt.show()\n",
    "acc_fig.savefig('4layer_encoder_decoder_accuracy.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load best weights and save final model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load best weights form training\n",
    "encoder_decoder.load_weights(best_weights_filepath)\n",
    "\n",
    "# Save final model\n",
    "filepath = \"4layer_encoder_decoder.mod\"\n",
    "encoder_decoder.save(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. U-Net Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters for model and training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Params\n",
    "optimizer=Adam(2e-4)\n",
    "loss='mean_squared_error'\n",
    "\n",
    "# Training Params\n",
    "best_weights_filepath = 'UNet_best_weights.hdf5'\n",
    "epochs = 10\n",
    "batch_size = 10\n",
    "validation_split=0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build U-Net model architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = Input(shape=x_data.shape[1:])\n",
    "\n",
    "c1 = Conv2D(filters=8, kernel_size=(3,3), activation='relu', padding='same')(input_layer)\n",
    "l = MaxPool2D(strides=(2,2))(c1)\n",
    "\n",
    "c2 = Conv2D(filters=16, kernel_size=(3,3), activation='relu', padding='same')(l)\n",
    "l = MaxPool2D(strides=(2,2))(c2)\n",
    "\n",
    "c3 = Conv2D(filters=32, kernel_size=(3,3), activation='relu', padding='same')(l)\n",
    "l = MaxPool2D(strides=(2,2))(c3)\n",
    "\n",
    "c4 = Conv2D(filters=32, kernel_size=(1,1), activation='relu', padding='same')(l)\n",
    "\n",
    "\n",
    "l = concatenate([UpSampling2D(size=(2,2))(c4), c3], axis=-1)\n",
    "l = Conv2D(filters=32, kernel_size=(2,2), activation='relu', padding='same')(l)\n",
    "l = concatenate([UpSampling2D(size=(2,2))(l), c2], axis=-1)\n",
    "l = Conv2D(filters=24, kernel_size=(2,2), activation='relu', padding='same')(l)\n",
    "l = concatenate([UpSampling2D(size=(2,2))(l), c1], axis=-1)\n",
    "l = Conv2D(filters=16, kernel_size=(2,2), activation='relu', padding='same')(l)\n",
    "l = Conv2D(filters=64, kernel_size=(1,1), activation='relu')(l)\n",
    "l = Dropout(0.5)(l)\n",
    "output_layer = Conv2D(filters=3, kernel_size=(1,1), activation='sigmoid')(l)\n",
    "                                                         \n",
    "UNet = Model(input_layer, output_layer)\n",
    "\n",
    "UNet.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile U-Net model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNet.compile(optimizer=optimizer, loss=loss,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train U-Net model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save best weights of model dependent on the lowest validation loss to load for testing\n",
    "mcp = ModelCheckpoint(best_weights_filepath, monitor=\"val_loss\",\n",
    "                      save_best_only=True, save_weights_only=False)\n",
    "\n",
    "# Train model\n",
    "history =UNet.fit(x_data, y_data,\n",
    "                epochs=epochs,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=True,\n",
    "                validation_split=validation_split,\n",
    "                        callbacks = [mcp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "loss_fig = plt.figure()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(loss, 'blue', label='Training Loss')\n",
    "plt.plot(val_loss, 'green', label='Validation Loss')\n",
    "plt.xticks(range(0,epochs)[0::2])\n",
    "plt.legend()\n",
    "plt.show()\n",
    "loss_fig.savefig('UNet_loss.png')\n",
    "\n",
    "\n",
    "acc_fig = plt.figure()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(acc, 'blue', label='Training Accuracy')\n",
    "plt.plot(val_acc, 'green', label='Validation Accuracy')\n",
    "plt.xticks(range(0,epochs)[0::2])\n",
    "plt.legend()\n",
    "plt.show()\n",
    "acc_fig.savefig('UNet_accuracy.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load best weights and save final U-Net model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best weights form training\n",
    "UNet.load_weights(best_weights_filepath)\n",
    "\n",
    "# Save final model\n",
    "filepath = \"UNet.mod\"\n",
    "UNet.save(filepath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
